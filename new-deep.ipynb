{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # import libraries \nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport itertools\nimport csv,codecs,nltk,re\nfrom nltk.stem.isri import ISRIStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport itertools\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_validate\n#from sklearn import cross_validation#    from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.svm import SVC, NuSVC , LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import *\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\ntf.config.run_functions_eagerly(True)\ntf.data.experimental.enable_debug_mode()\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Bidirectional\nfrom keras.layers import Activation","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:41.872242Z","iopub.execute_input":"2023-03-27T13:19:41.872654Z","iopub.status.idle":"2023-03-27T13:19:41.886085Z","shell.execute_reply.started":"2023-03-27T13:19:41.872613Z","shell.execute_reply":"2023-03-27T13:19:41.884381Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"# Read the dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cyberbullying-dataset/twitter_racism_parsed_dataset.csv')\n\ntexts = data['Text'].astype(str)\nlabels = data['oh_label'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:41.888674Z","iopub.execute_input":"2023-03-27T13:19:41.889781Z","iopub.status.idle":"2023-03-27T13:19:41.951648Z","shell.execute_reply.started":"2023-03-27T13:19:41.889741Z","shell.execute_reply":"2023-03-27T13:19:41.950461Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"markdown","source":"# text preprocessing","metadata":{}},{"cell_type":"code","source":"def stopwordremoval(Text):\n    stop=stopwords.words('english')\n    needed_words=[]\n    words=word_tokenize(Text)\n    for w in words:\n         if len(w)>=2 and w not in stop:\n                needed_words.append(w)\n    filterd_sent= \" \".join(needed_words)\n    return filterd_sent\ndef stemming(Text):\n    st = ISRIStemmer()\n    stemmed_words=[]\n    words=word_tokenize(Text)\n    for w in words:\n        stemmed_words.append(st.stem(w))\n    stemmed_sent=\" \".join(stemmed_words)\n    return stemmed_sent\ndef preparedatasets(data):\n    sentences=[]\n    for index,r in data.iterrows():\n        Text=stopwordremoval(r['Text'])\n        Text=stemming(r['Text'])\n        sentences.append([r['Text'],r['oh_label']])\n    df_sentence=DataFrame(sentences, columns=[\"Text\", \"oh_label\"])\n    return df_sentence  ","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:41.953465Z","iopub.execute_input":"2023-03-27T13:19:41.953801Z","iopub.status.idle":"2023-03-27T13:19:41.963633Z","shell.execute_reply.started":"2023-03-27T13:19:41.953770Z","shell.execute_reply":"2023-03-27T13:19:41.962317Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"data=preparedatasets(data)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-03-27T13:19:41.965147Z","iopub.execute_input":"2023-03-27T13:19:41.966363Z","iopub.status.idle":"2023-03-27T13:19:56.782448Z","shell.execute_reply.started":"2023-03-27T13:19:41.966322Z","shell.execute_reply":"2023-03-27T13:19:56.781199Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"#data=preparedatasets(data)\ndata.dropna(inplace=True)\ndata.head()\ndata['word_count'] = data['Text'].apply(lambda x: len(str(x).split()))\n#Remove 0 and 1 word_count posts\nnew_data=data[(data.word_count >1)]\nnew_data.describe()    \ndata=new_data","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:56.785136Z","iopub.execute_input":"2023-03-27T13:19:56.785485Z","iopub.status.idle":"2023-03-27T13:19:56.831967Z","shell.execute_reply.started":"2023-03-27T13:19:56.785453Z","shell.execute_reply":"2023-03-27T13:19:56.830601Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"data=data.drop_duplicates( keep=\"first\")","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:56.833589Z","iopub.execute_input":"2023-03-27T13:19:56.833915Z","iopub.status.idle":"2023-03-27T13:19:56.849286Z","shell.execute_reply.started":"2023-03-27T13:19:56.833883Z","shell.execute_reply":"2023-03-27T13:19:56.847987Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data\ntexts = data['Text'].astype(str)\nlabels = data['oh_label'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:56.851236Z","iopub.execute_input":"2023-03-27T13:19:56.851693Z","iopub.status.idle":"2023-03-27T13:19:56.858693Z","shell.execute_reply.started":"2023-03-27T13:19:56.851656Z","shell.execute_reply":"2023-03-27T13:19:56.857501Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"    #X_train, X_test, y_train, y_test = \\\n    #train_test_split(data['Text'], data['oh_label'],test_size=0.20, random_state = 0)\n    #vectorizer = TfidfVectorizer( analyzer='word',smooth_idf=True, ngram_range=(1,2))\n    #vectorizer.fit(X_train)\n    #X_train_vectorized = vectorizer.transform(X_train)\n    \n   # Tokenize the text data\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(texts)\ntext_sequences = tokenizer.texts_to_sequences(texts)\ntext_data = keras.preprocessing.sequence.pad_sequences(text_sequences)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(text_data, labels, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:56.860124Z","iopub.execute_input":"2023-03-27T13:19:56.861019Z","iopub.status.idle":"2023-03-27T13:19:57.602609Z","shell.execute_reply.started":"2023-03-27T13:19:56.860980Z","shell.execute_reply":"2023-03-27T13:19:57.600819Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"# ---------- ML Algorithms-----------\n#cl=MultinomialNB()\n#cl=LogisticRegression()\n#cl=SVC()\n#cl=DecisionTreeClassifier()\n#cl=RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:57.605178Z","iopub.execute_input":"2023-03-27T13:19:57.605613Z","iopub.status.idle":"2023-03-27T13:19:57.612291Z","shell.execute_reply.started":"2023-03-27T13:19:57.605578Z","shell.execute_reply":"2023-03-27T13:19:57.610660Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# ---------- Deep Learning Algorithms ----------\n\n# ------------  LSTM --------------\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(5000, 32, input_length=text_data.shape[1]))\nmodel.add(keras.layers.LSTM(32))\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:57.616904Z","iopub.execute_input":"2023-03-27T13:19:57.617327Z","iopub.status.idle":"2023-03-27T13:19:57.968845Z","shell.execute_reply.started":"2023-03-27T13:19:57.617289Z","shell.execute_reply":"2023-03-27T13:19:57.967150Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:57.970752Z","iopub.execute_input":"2023-03-27T13:19:57.971281Z","iopub.status.idle":"2023-03-27T13:19:57.985250Z","shell.execute_reply.started":"2023-03-27T13:19:57.971214Z","shell.execute_reply":"2023-03-27T13:19:57.984307Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"#Number of words in the dataset\ndef get_count(data):\n    d2=[]\n    tt=\"\"\n    for index,r in data.iterrows():\n        d2.append((r['Text'] ))\n        tt+=r['Text']\n    return len(tt)  ","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:57.986939Z","iopub.execute_input":"2023-03-27T13:19:57.988211Z","iopub.status.idle":"2023-03-27T13:19:57.995650Z","shell.execute_reply.started":"2023-03-27T13:19:57.988158Z","shell.execute_reply":"2023-03-27T13:19:57.994299Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"#cl.fit(X_train_vectorized, y_train)\n\nhistory=model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-27T13:19:57.997239Z","iopub.execute_input":"2023-03-27T13:19:57.997682Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/structured_function.py:257: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n","output_type":"stream"},{"name":"stdout","text":"337/337 [==============================] - 50s 149ms/step - loss: 0.2852 - accuracy: 0.8915 - val_loss: 0.1943 - val_accuracy: 0.9174\nEpoch 2/10\n337/337 [==============================] - 50s 149ms/step - loss: 0.1445 - accuracy: 0.9421 - val_loss: 0.1915 - val_accuracy: 0.9174\nEpoch 3/10\n337/337 [==============================] - 51s 151ms/step - loss: 0.1032 - accuracy: 0.9597 - val_loss: 0.2100 - val_accuracy: 0.9193\nEpoch 4/10\n337/337 [==============================] - 50s 150ms/step - loss: 0.0795 - accuracy: 0.9701 - val_loss: 0.2432 - val_accuracy: 0.9178\nEpoch 5/10\n337/337 [==============================] - 51s 151ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.2692 - val_accuracy: 0.9137\nEpoch 6/10\n303/337 [=========================>....] - ETA: 4s - loss: 0.0414 - accuracy: 0.9860","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = cl.predict(vectorizer.transform(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the evaluation metrics\nprint('Accuracy:', accuracy)\nprint('Precision:', precision)\nprint('Recall:', recall)\nprint('F1 Score:', f1)\nprint('Confusion Matrix:', cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}